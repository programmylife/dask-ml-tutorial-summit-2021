{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Universal Custom Estimators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Patterns for Adding Custom Functionality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What can go wrong and why is it important to get this right"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=============================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lessons Learned and Best Practices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Follow the sci-kit learn API: https://scikit-learn.org/stable/developers/develop.html#rolling-your-own-estimator\n",
    "- Favor array-like interface data structures internally in estimators. These work better across numpy, Dask, and Rapids that dataframe collections. If you need dataframe operations (like groupby, etc.) consider moving those to a transformer and converting to an array-like for processing.\n",
    "- All attributes learned during .fit should be concrete, i.e. they should not be dask collections.\n",
    "- To the extent possible, transformers should support\n",
    "        numpy.ndarray\n",
    "        pandas.DataFrame\n",
    "        dask.Array\n",
    "        dask.DataFrame\n",
    "- If possible, transformers should accept a columns keyword to limit the transformation to just those columns, while passing through other columns untouched. inverse_transform should behave similarly (ignoring other columns) so that inverse_transform(transform(X)) equals X.\n",
    "- Methods returning arrays (like .transform, .predict), should return the same type as the input. So if a dask.array is passed in, a dask.array with the same chunks should be returned.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "last 4 from: https://ml.dask.org/contributing.html#conventions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extend `dask-ml` Using a Real World Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Setup/data\n",
    "- Simple custom transformer (maybe fillna or similar?)\n",
    "- transformer for adding columns (this will allow us to differentiate between dask and pandas)\n",
    "- custom estimator\n",
    "- make the previous steps into a pipeline (look at the beginning of the GTC talk and find the part where Mike talks about not running fit a second time. Might want todo something with that to show the value of a pipeline here.\n",
    "- Grid search - show running their pipeline with grid search to find the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "\n",
    "X, y = make_classification(\n",
    "    n_samples=100_000,\n",
    "    n_features=100,\n",
    "    weights=[0.75, 0.25],\n",
    "    flip_y=0.75,\n",
    "    random_state=123,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformer 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from abc import ABCMeta\n",
    "\n",
    "class Mutate(TransformerMixin, BaseEstimator, metaclass=ABCMeta):\n",
    "    def fit(self, X, y):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        \"\"\"Mutates X\"\"\"\n",
    "        X = X + 1\n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Should we do a transformer 2? Maybe have #1 be transforming to DF then 2 be adding a column (to differentiate between dask and pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger('exp a')\n",
    "\n",
    "class CustomEstimator(BaseEstimator):    \n",
    "    def __init__(self, estimator, logger):\n",
    "        self.estimator = estimator        \n",
    "        self.logger = logger\n",
    "    \n",
    "    def fit(self, X, y=None, **fit_kws):\n",
    "        self.estimator.fit(X, y)        \n",
    "        self.logger.info(\"... log things ...\")\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CustomEstimator(estimator=XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "                                        colsample_bylevel=1, colsample_bynode=1,\n",
       "                                        colsample_bytree=1, eval_metric='error',\n",
       "                                        gamma=0, gpu_id=-1,\n",
       "                                        importance_type='gain',\n",
       "                                        interaction_constraints='',\n",
       "                                        learning_rate=0.300000012,\n",
       "                                        max_delta_step=0, max_depth=6,\n",
       "                                        min_child_weight=1, missing=nan,\n",
       "                                        monotone_constraints='()',\n",
       "                                        n_estimators=100, n_jobs=-1,\n",
       "                                        num_parallel_tree=1, random_state=0,\n",
       "                                        reg_alpha=0, reg_lambda=1,\n",
       "                                        scale_pos_weight=1, subsample=1,\n",
       "                                        tree_method='exact',\n",
       "                                        use_label_encoder=False,\n",
       "                                        validate_parameters=1, verbosity=None),\n",
       "                logger=<Logger exp a (WARNING)>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "clf = CustomEstimator(xgb.XGBClassifier(n_jobs=-1, eval_metric='error', use_label_encoder=False), logger)\n",
    "\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb.best_estimator # or something to show we trained the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask_ml.datasets import make_classification as make_classification_dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dask, y_dask = make_classification_dask(\n",
    "    n_samples=100_000,\n",
    "    n_features=100,\n",
    "    weights=[0.75, 0.25],\n",
    "    flip_y=0.75,\n",
    "    random_state=123,\n",
    "    chunks=1000,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://127.0.0.1:41863</li>\n",
       "  <li><b>Dashboard: </b><a href='http://127.0.0.1:8787/status' target='_blank'>http://127.0.0.1:8787/status</a></li>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>4</li>\n",
       "  <li><b>Cores: </b>8</li>\n",
       "  <li><b>Memory: </b>24.92 GiB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://127.0.0.1:41863' processes=4 threads=8, memory=24.92 GiB>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dask.distributed import Client, progress\n",
    "client = Client()\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hide solutions and add a blank cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CustomEstimator(estimator=DaskXGBClassifier(base_score=0.5, booster='gbtree',\n",
       "                                            colsample_bylevel=1,\n",
       "                                            colsample_bynode=1,\n",
       "                                            colsample_bytree=1,\n",
       "                                            eval_metric='error', gamma=0,\n",
       "                                            gpu_id=-1,\n",
       "                                            interaction_constraints='',\n",
       "                                            learning_rate=0.300000012,\n",
       "                                            max_delta_step=0, max_depth=6,\n",
       "                                            min_child_weight=1,\n",
       "                                            monotone_constraints='()',\n",
       "                                            n_jobs=-1, num_parallel_tree=1,\n",
       "                                            objective='binary:logistic',\n",
       "                                            random_state=0, reg_alpha=0,\n",
       "                                            reg_lambda=1, scale_pos_weight=1,\n",
       "                                            subsample=1, tree_method='approx',\n",
       "                                            use_label_encoder=False,\n",
       "                                            validate_parameters=1),\n",
       "                logger=<Logger exp a (WARNING)>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost.dask as dxgb\n",
    "\n",
    "clf = CustomEstimator(dxgb.DaskXGBClassifier(n_jobs=-1, eval_metric='error', use_label_encoder=False), logger)\n",
    "\n",
    "clf.fit(X_dask, y_dask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# maybe write an updated estimator with the implemented cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# have them write their own CV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
